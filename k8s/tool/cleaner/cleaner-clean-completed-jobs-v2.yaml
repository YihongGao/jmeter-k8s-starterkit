---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cleaner
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: my-completed-jobs-cleaner-role
rules:
- apiGroups: ["batch"]
  resources: ["jobs"]
  verbs: ["list", "delete"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-completed-jobs-cleaner-rolebinding
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-completed-jobs-cleaner-role
subjects:
- kind: ServiceAccount
  name: cleaner
  namespace: default
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cleaner-script

  labels:
    k8s-app: cleaner
data:
  clean.sh: |+
    #!/bin/sh
    set -x 
    COMMANDS=$(kubectl get pod --no-headers -o=custom-columns=NAME:.metadata.name --selector=jmeter_mode=master)
    echo "COMMANDS: ${COMMANDS}"
    for pod_name in ${COMMANDS}; do 
      echo "job name: ${pod_name}"
      status=$(kubectl describe pod ${pod_name} | grep Reason: | awk -F " " '{print $2}')
      if [ "${status}" = "Completed" ]; then
        echo "${pod_name} is completed."
        job_name=$(kubectl get pod ${pod_name} -o=jsonpath='{.metadata.labels.app}')
        echo "job_name: ${job_name}"
        kubectl delete jobs ${job_name}
        kubectl delete jobs --selector=master_job=${job_name}
      fi
    done
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: jobs-cleanup
spec:
  schedule: "*/1 * * * *"
  successfulJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: cleaner
          containers:
          - name: kubectl-container
            image: bitnami/kubectl:latest
            command: ["sh", "/tmp/clean.sh"]
            volumeMounts:
            - name: cleaner-script
              mountPath: /tmp/
          restartPolicy: Never
          volumes:
          - name: cleaner-script
            configMap:
              name: cleaner-script